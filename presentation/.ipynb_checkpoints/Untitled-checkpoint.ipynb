{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presentation - Gaussian Processes\n",
    "\n",
    "Why?:\n",
    "As described earlier, the power of Gaussian processes lies in the choice of the kernel function. This property allows experts to introduce domain knowledge into the process and lends Gaussian processes their flexibility to capture trends in the training data.\n",
    "\n",
    "Gaussian Processes can help us with regression. Consider trying to fit a regression to a number of points. There are infinitely possible functions that could do this. Optimally, we want to find the most probable line, while also estimating how uncertain our guess is. Gaussian Processes are a way to generate *a lot* of candidate functions which fit the data. We can then view these functions as a distribution of candidate models. We can then use our normal Bayesian tricks - the mean of this distribution is our best guess for the function, while the variance gives us an estimate of how unsure we are in our choice. \n",
    "\n",
    "A Gaussian Process is the generalization of the Gaussian distribution to infinitely many dimensions. \n",
    "\n",
    "What we are trying to learn is the underlying covariance matrix; how does the different points relate to each other?\n",
    "\n",
    "how do we set up this distribution and define the mean $\\mu$ and the covariance matrix $\\Sigma$? The covariance matrix $\\Sigma$ is determined by its covariance function kk, which is often also called the kernel of the Gaussian process. We will talk about this in detail in the next section. But before we come to this, let us reflect on how we can use multivariate Gaussian distributions to estimate function values. \n",
    "\n",
    "These cacn be found using kernels (remember SVMs?). Kernels need to symmetric positive definite matrices. This is because we want a measure of similarity in the end, don't worry about it. \n",
    "\n",
    "Error term: By adding an error term to our covariance matrix, we can also model measurement errors, and thus not be restricted by what the actual measures of $y$ was. \n",
    "\n",
    "$$\\epsilon \\sim \\mathcal{N}(0, \\psi^2)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
