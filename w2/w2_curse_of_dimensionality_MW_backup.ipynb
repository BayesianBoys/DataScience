{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('datas': conda)",
   "metadata": {
    "interpreter": {
     "hash": "9f85d914290606a323cc56de9435b7942af32f60051201343944f78468ca5820"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Week 2: Model Selection & Curse of Dimensionality"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Your task for today is to create the __most generalizable__ model from datasets of different sizes. \n",
    "\n",
    "We will use 3 partitions of the [Titanic](https://www.kaggle.com/c/titanic) dataset of size 100, 400, and 891. This is a fairly straightforward binary classification task with the goal of predicting _who survived_0 when the Titanic sunk. \n",
    "\n",
    "The dataset has the following columns: \n",
    "\n",
    "| Variable | Definition                                 | Key                                            |   |   |\n",
    "|:----------|:--------------------------------------------|:------------------------------------------------|---|---|\n",
    "| Survival | Survival                                   | 0 = No, 1 = Yes                                |   |   |\n",
    "| Pclass   | Ticket class                               | 1 = 1st, 2 = 2nd, 3 = 3rd                      |   |   |\n",
    "| Sex      | Sex                                        |                                                |   |   |\n",
    "| Age      | Age in years                               |                                                |   |   |\n",
    "| Sibsp    | # of siblings / spouses aboard the Titanic |                                                |   |   |\n",
    "| Parch    | # of parents / children aboard the Titanic |                                                |   |   |\n",
    "| Ticket   | Ticket number                              |                                                |   |   |\n",
    "| Fare     | Passenger fare                             |                                                |   |   |\n",
    "| Cabin    | Cabin number                               |                                                |   |   |\n",
    "| Embarked | Port of Embarkation                        | C = Cherbourg, Q = Queenstown, S = Southampton |   |   |\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "There are some pecularities in the data: some columns contain missing values, some are redundant, and some might only be useful with feature engineering.\n",
    "\n",
    "__Exercise__:\n",
    "\n",
    "The following shows a simple example of fitting a logistic regression model to the data with 400 training examples.\n",
    "\n",
    "- Run the code and discuss ways to improve it"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"titanic\" # set to the name of the folder where you keep the data\n",
    "test = pd.read_csv(os.path.join(data_folder, \"test.csv\"))\n",
    "#train = pd.read_csv(os.path.join(data_folder, \"train_100.csv\"))\n",
    "#train = pd.read_csv(os.path.join(data_folder, \"train_400.csv\"))\n",
    "train = pd.read_csv(os.path.join(data_folder, \"train_full.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age             86\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "Survived         0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "# And the test set\n",
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, lots of missing age values. Filling them with the mean value of the column\n",
    "#train[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].mean())\n",
    "#test[\"Age\"] = test[\"Age\"].fillna(train[\"Age\"].mean())\n",
    "\n",
    "# 1 missing Fare in test, filling with the mean\n",
    "test[\"Fare\"] = test[\"Fare\"].fillna(train[\"Fare\"].mean())\n",
    "\n",
    "# Mean imputation is very naive - can you think of better ways to impute the missing values?\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Fill age based on the distribution of remaining values:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Train\n",
    "#Get distribution\n",
    "train_ages = train.Age.value_counts(normalize=True)\n",
    "#Get missing indexes\n",
    "missing = train['Age'].isnull()\n",
    "#Randomly sample from age distribution and assign missing values\n",
    "train.loc[missing,'Age'] = np.random.choice(train_ages.index, size=len(train[missing]),p=train_ages.values)\n",
    "\n",
    "##test\n",
    "#Get distribution\n",
    "test_ages = test.Age.value_counts(normalize=True)\n",
    "#Get missing indexes\n",
    "missing2 = test['Age'].isnull()\n",
    "#Randomly sample from age distribution and assign missing values\n",
    "test.loc[missing2,'Age'] = np.random.choice(test_ages.index, size=len(test[missing2]),p=test_ages.values)"
   ]
  },
  {
   "source": [
    "# Let's see if it worked\n",
    "train.isnull().sum()\n",
    "#test.isnull().sum()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 38,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age              0\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "Survived         0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ]
  },
  {
   "source": [
    "# Feature Engineering:\n",
    "## Cabin_binary:\n",
    "Binary, records whether logs had an NA or not \n",
    "\n",
    "## Family_size:\n",
    "Integer, sums the number of siblings and children of the passenger\n",
    "\n",
    "## Age_bin:\n",
    "Bins the different age groups into children ($age \\leq 14$), adult ($15 \\leq age \\leq 39$) and old ($40 \\leq age$ )"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_cabin(df):\n",
    "   cabins = df[\"Cabin\"].values\n",
    "   df[\"Cabin_binary\"] = [1 if isinstance(cabin, str) else 0 for cabin in cabins]\n",
    "   return df\n",
    "\n",
    "def get_family_size(df):\n",
    "   siblings, children = df[\"SibSp\"].values, df[\"Parch\"].values\n",
    "   df[\"Family_size\"] = [siblings[i] + children[i] for i in range(len(siblings))]\n",
    "   return df\n",
    "\n",
    "def bin_age(age):\n",
    "   if age < 15:\n",
    "      return \"child\"\n",
    "   elif age < 40:\n",
    "      return \"adult\"\n",
    "   else:\n",
    "      return \"old\"   \n",
    "\n",
    "train, test = binarize_cabin(train), binarize_cabin(test)\n",
    "train, test = get_family_size(train), get_family_size(test)\n",
    "\n",
    "train[\"Age_bin\"] = train[\"Age\"].apply(lambda x: bin_age(x))\n",
    "test[\"Age_bin\"] = test[\"Age\"].apply(lambda x: bin_age(x))"
   ]
  },
  {
   "source": [
    "# Constructing dummy variables (splitting and binarizing)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn does not like columns with  categorical values\n",
    "# make them binary dummy variables instead\n",
    "train = pd.get_dummies(train, columns=[\"Pclass\", \"Embarked\", \"Sex\", \"Age_bin\"])\n",
    "test =  pd.get_dummies(test, columns=[\"Pclass\", \"Embarked\", \"Sex\", \"Age_bin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "source": [
    "# Drop uninformative columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PassengerId, Name, and Ticket are practically unique for each individual and thus unusable for predictions\n",
    "# Cabin has a lot of missing values and a lot of unique values. Dropping the columns\n",
    "\n",
    "uninformative_cols = [\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\", \"Parch\", \"SibSp\", \"Embarked_C\", \"Embarked_Q\", \"Embarked_S\", \"Age\", \"Fare\", \"Pclass_2\", \"Age_bin_adult\"] #\n",
    "train = train.drop(columns=uninformative_cols)\n",
    "test = test.drop(columns=uninformative_cols)\n",
    "\n",
    "# Could Cabin be made informative with some feature engineering?"
   ]
  },
  {
   "source": [
    "# Readying the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make subset of training data containing everything except the label\n",
    "X = train.loc[:, train.columns != \"Survived\"]\n",
    "# Make subset containing only the label\n",
    "Y = train[\"Survived\"]\n",
    "X_test = test.loc[:, train.columns != \"Survived\"]\n",
    "Y_test = test[\"Survived\"]"
   ]
  },
  {
   "source": [
    ".. That was not very impressive. Our expectation of performance was horribly miscalibrated, as we fared much worse on the test set than on our training set. Our model also seems to overpredict survival on the test data.\n",
    "\n",
    "Now it's your turn to do better\n",
    "\n",
    "__Exercises__:\n",
    "\n",
    "Discuss:\n",
    "\n",
    "- How can you get a better estimate of the out-of-sample performance?\n",
    "- How can you reduce overfitting to the training data?\n",
    "- Do you need different strategies for model creation for the different sizes of dataset?\n",
    "    - If so, what would you do differently?\n",
    "\n",
    "Code:\n",
    "\n",
    "- For each partition (i.e. each dataset) create at least 3 different models that you expect to generalize well. Evaluate them on the training sample using some form of model selection (cross-validated performance, held-out data, information criteria etc.) and choose one to test on the testing set. Your goal is to create the best performing, most well-calibrated model, ie. training performance should be close to testing performance (and performance should of course be high!). \n",
    "- Test how good performance you can get on the small datasets with clever optimization and regularization.\n",
    "\n",
    "For next time:\n",
    "\n",
    "- In your study groups, prepare a 3-5 min presentation on something interesting about your solution: Did you create some cool functions for preprocessing, test an exciting new type of model, set everything up to be run from the command line, or perhaps you're just really excited about the performance of your model. No need for slideshows, but feel free to show code.\n",
    "\n",
    "---\n",
    "\n",
    "Tips to get started:\n",
    "- Visualization can often be a good way to get started: how is the distribution of the variables? are any of them highly correlated?\n",
    "- Instead of training and testing on the whole training data, implement a form of cross-validation ([sk-learn makes it easy](https://scikit-learn.org/stable/modules/cross_validation.html#computing-cross-validated-metrics))\n",
    "- Remember ridge regularization from last week? [Try it](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html)\n",
    "- Check out a list of models in sk-learn [here](https://scikit-learn.org/stable/supervised_learning.html)\n",
    "- Lost or out of ideas? Take some inspiration from entries in the [original Kaggle challenge](https://www.kaggle.com/c/titanic/code)\n",
    "\n",
    "Things to try:\n",
    "- You might be able to get more information out of the predictors if you do some feature engineering. Perhaps add a column indicating whether the person had a cabin or not, or one calculating the family size?\n",
    "- Calculating information criteriais not entirely straight-forward in sk-learn. [This tutorial](https://machinelearningmastery.com/probabilistic-model-selection-measures/) might help\n",
    "- The outcome (survival) is not completely balanced. Over-/under-sampling might help\n",
    "- Ensemble models often generalize better than single models. Try one of the methods [here](https://scikit-learn.org/stable/modules/ensemble.html)\n",
    "- Don't feel restricted to sk-learn. Feel to make a Bayesian model in [PyMC3](https://github.com/pymc-devs/pymc3) or any other framework you want\n",
    "- High-performance interpretable models are all the rage right now. [Try one of them!](https://github.com/interpretml/interpret) \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Main Function\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "import re\n",
    "\n",
    "def get_cross(model_inst, X, Y, cv = 8, scoring = \"f1_weighted\"):\n",
    "    model = model_inst\n",
    "    model.fit(X, Y)\n",
    "    yhat = model.predict(X)\n",
    "    acc_train = accuracy_score(Y, yhat)\n",
    "    yhat_test = model.predict(X_test)\n",
    "    acc_test = accuracy_score(Y_test, yhat_test)\n",
    "    scores = cross_val_score(model_inst, X, Y, cv=8, scoring = \"f1_weighted\")\n",
    "    print(f\"mean = {np.mean(scores)}, sd = {np.std(scores)}\")\n",
    "    return {\"acc_train\": acc_train, \"acc_test\": acc_test, \"mean_cross\": np.mean(scores), \"std_cross\": np.std(scores), \"conf_mat\": confusion_matrix(Y, yhat)}\n",
    "\n",
    "### NESTED DICT APPROACH:\n",
    "\n",
    "list_of_models = [LogisticRegression(), RandomForestClassifier(n_estimators = 60, n_jobs = -1, random_state = 42), MLPClassifier(solver = \"adam\", alpha = 0.001, hidden_layer_sizes=(1000,100)), RidgeClassifier(), AdaBoostClassifier()]\n",
    "\n",
    "model_performance = {re.split(\"\\(\", str(i))[0]: get_cross(i, X, Y) for i in list_of_models}\n",
    "\n",
    "model_performance"
   ]
  },
  {
   "source": [
    "# Indexing the dictionary"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance[\"RidgeClassifier\"][\"acc_train\"]"
   ]
  },
  {
   "source": [
    "## But obviously, you can't interpret these and look under the hood...\n",
    "# OR CAN YOU?!\n",
    "Introducing glassbox modeling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.glassbox import LogisticRegression, ExplainableBoostingClassifier\n",
    "#from interpret.greybox import DecisionTreeClassifier\n",
    "from interpret import show\n",
    "\n",
    "ebm_log = LogisticRegression()\n",
    "ebm_log.fit(X, Y)\n",
    "\n",
    "emb_exp = ExplainableBoostingClassifier()\n",
    "emb_exp.fit(X,Y)\n",
    "\n",
    "ebm_global = emb_exp.explain_global()\n",
    "show(ebm_global)\n",
    "\n",
    "ebm_global = ebm_log.explain_global()\n",
    "show(ebm_global)\n",
    "\n",
    "# or substitute with LogisticRegression, DecisionTreeClassifier, RuleListClassifier, ...\n",
    "# EBM supports pandas dataframes, numpy arrays, and handles \"string\" data natively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test = emb_exp.predict(X_test)\n",
    "print(f\"Accuracy on test data: {accuracy_score(Y_test, y_hat_test)}\")\n",
    "#confusion_matrix(Y_test, y_hat_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(Y_test, y_hat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.glassbox import ClassificationTree\n",
    "\n",
    "emb_ct = ClassificationTree()\n",
    "emb_ct.fit(X, Y)\n",
    "\n",
    "ebm_global = emb_ct.explain_global()\n",
    "show(ebm_global)\n",
    "\n",
    "y_hat_test = emb_ct.predict(X_test)\n",
    "print(f\"Accuracy on test data: {accuracy_score(Y_test, y_hat_test)}\")\n",
    "confusion_matrix(Y_test, y_hat_test)\n"
   ]
  },
  {
   "source": [
    "# What would Bayes have done?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import arviz as az\n",
    "import pymc3 as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "# Initialize random number generator\n",
    "RANDOM_SEED = 8927\n",
    "np.random.seed(RANDOM_SEED)\n",
    "az.style.use(\"arviz-darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = train.columns\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theano tensor import. \n",
    "import theano.tensor as T\n",
    "\n",
    "# logistic \n",
    "def logistic(l):\n",
    "    return 1 / (1 + T.exp(-l))\n",
    "\n",
    "# make the model\n",
    "basic_model = pm.Model()\n",
    "\n",
    "with basic_model:\n",
    "    \n",
    "    #data = pm.Data('data', x)\n",
    "    \n",
    "    # Priors for unknown model parameters\n",
    "    alpha = pm.Normal(\"alpha\", mu = 0, sigma = 1)\n",
    "    beta = pm.Normal(\"beta\", mu = 0, sigma = 1, shape = 9) # shape = 3 since we have 3 predictors. \n",
    "    \n",
    "    # Expected value of outcome\n",
    "    mu = alpha + beta[0] * train[columns[1]].values + beta[1] * train[columns[2]].values + beta[2] * train[columns[3]].values + beta[3] * train[columns[4]].values + beta[4] * train[columns[5]].values + beta[5] * train[columns[6]].values + beta[5] * train[columns[6]].values + beta[6] * train[columns[7]].values + beta[7] * train[columns[9]].values + beta[8] * train[columns[10]].values\n",
    "\n",
    "    # Likelihood (sampling distribution) of observations\n",
    "    Y_obs = pm.Bernoulli('Y_obs', p=logistic(mu), observed = train[columns[0]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_estimate = pm.find_MAP(model = basic_model)\n",
    "map_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with basic_model:\n",
    "    # instantiate sampler\n",
    "    step = pm.Slice()\n",
    "\n",
    "    # draw 5000 posterior samples\n",
    "    trace = pm.sample(5000, step=step, return_inferencedata=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with basic_model:\n",
    "    az.plot_trace(trace);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with basic_model:\n",
    "    display(az.summary(trace, round_to=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}