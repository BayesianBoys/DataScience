{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('cogmod': conda)",
   "metadata": {
    "interpreter": {
     "hash": "2a6a24a5190e491147426ac0487f2bba0d237e15c1dc564deaa9c1e3a574abbe"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Week 2: Model Selection & Curse of Dimensionality"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Your task for today is to create the __most generalizable__ model from datasets of different sizes. \n",
    "\n",
    "We will use 3 partitions of the [Titanic](https://www.kaggle.com/c/titanic) dataset of size 100, 400, and 891. This is a fairly straightforward binary classification task with the goal of predicting _who survived_0 when the Titanic sunk. \n",
    "\n",
    "The dataset has the following columns: \n",
    "\n",
    "| Variable | Definition                                 | Key                                            |   |   |\n",
    "|:----------|:--------------------------------------------|:------------------------------------------------|---|---|\n",
    "| Survival | Survival                                   | 0 = No, 1 = Yes                                |   |   |\n",
    "| Pclass   | Ticket class                               | 1 = 1st, 2 = 2nd, 3 = 3rd                      |   |   |\n",
    "| Sex      | Sex                                        |                                                |   |   |\n",
    "| Age      | Age in years                               |                                                |   |   |\n",
    "| Sibsp    | # of siblings / spouses aboard the Titanic |                                                |   |   |\n",
    "| Parch    | # of parents / children aboard the Titanic |                                                |   |   |\n",
    "| Ticket   | Ticket number                              |                                                |   |   |\n",
    "| Fare     | Passenger fare                             |                                                |   |   |\n",
    "| Cabin    | Cabin number                               |                                                |   |   |\n",
    "| Embarked | Port of Embarkation                        | C = Cherbourg, Q = Queenstown, S = Southampton |   |   |\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "There are some pecularities in the data: some columns contain missing values, some are redundant, and some might only be useful with feature engineering.\n",
    "\n",
    "__Exercise__:\n",
    "\n",
    "The following shows a simple example of fitting a logistic regression model to the data with 400 training examples.\n",
    "\n",
    "- Run the code and discuss ways to improve it"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"titanic\" # set to the name of the folder where you keep the data\n",
    "test = pd.read_csv(os.path.join(data_folder, \"test.csv\"))\n",
    "#train = pd.read_csv(os.path.join(data_folder, \"train_100.csv\"))\n",
    "#train = pd.read_csv(os.path.join(data_folder, \"train_400.csv\"))\n",
    "train = pd.read_csv(os.path.join(data_folder, \"train_full.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age             86\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "Survived         0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# And the test set\n",
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, lots of missing age values. Filling them with the mean value of the column\n",
    "#train[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].mean())\n",
    "#test[\"Age\"] = test[\"Age\"].fillna(train[\"Age\"].mean())\n",
    "\n",
    "# 1 missing Fare in test, filling with the mean\n",
    "test[\"Fare\"] = test[\"Fare\"].fillna(train[\"Fare\"].mean())\n",
    "\n",
    "# Mean imputation is very naive - can you think of better ways to impute the missing values?\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Fill age based on the distribution of remaining values:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Train\n",
    "#Get distribution\n",
    "train_ages = train.Age.value_counts(normalize=True)\n",
    "#Get missing indexes\n",
    "missing = train['Age'].isnull()\n",
    "#Randomly sample from age distribution and assign missing values\n",
    "train.loc[missing,'Age'] = np.random.choice(train_ages.index, size=len(train[missing]),p=train_ages.values)\n",
    "\n",
    "##test\n",
    "#Get distribution\n",
    "test_ages = test.Age.value_counts(normalize=True)\n",
    "#Get missing indexes\n",
    "missing2 = test['Age'].isnull()\n",
    "#Randomly sample from age distribution and assign missing values\n",
    "test.loc[missing2,'Age'] = np.random.choice(test_ages.index, size=len(test[missing2]),p=test_ages.values)"
   ]
  },
  {
   "source": [
    "# Let's see if it worked\n",
    "train.isnull().sum()\n",
    "\n",
    "train.head()\n",
    "#test.isnull().sum()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ]
  },
  {
   "source": [
    "# Feature Engineering:\n",
    "## Cabin_binary:\n",
    "Binary, records whether logs had an NA or not \n",
    "\n",
    "## Family_size:\n",
    "Integer, sums the number of siblings and children of the passenger\n",
    "\n",
    "## Age_bin:\n",
    "Bins the different age groups into children ($age \\leq 14$), adult ($15 \\leq age \\leq 39$) and old ($40 \\leq age$ )\n",
    "\n",
    "## Dashboard with data plots:\n",
    "https://datastudio.google.com/s/mK6oci_TYoU\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_cabin(df):\n",
    "   cabins = df[\"Cabin\"].values\n",
    "   df[\"Cabin_binary\"] = [1 if isinstance(cabin, str) else 0 for cabin in cabins]\n",
    "   return df\n",
    "\n",
    "def get_family_size(df):\n",
    "   siblings, children = df[\"SibSp\"].values, df[\"Parch\"].values\n",
    "   df[\"Family_size\"] = [siblings[i] + children[i] for i in range(len(siblings))]\n",
    "   return df\n",
    "\n",
    "def bin_age(age):\n",
    "   if age < 15:\n",
    "      return \"child\"\n",
    "   elif age < 40:\n",
    "      return \"adult\"\n",
    "   else:\n",
    "      return \"old\"   \n",
    "\n",
    "train, test = binarize_cabin(train), binarize_cabin(test)\n",
    "train, test = get_family_size(train), get_family_size(test)\n",
    "\n",
    "train[\"Age_bin\"] = train[\"Age\"].apply(lambda x: bin_age(x))\n",
    "test[\"Age_bin\"] = test[\"Age\"].apply(lambda x: bin_age(x))"
   ]
  },
  {
   "source": [
    "# Constructing dummy variables (splitting and binarizing)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn does not like columns with  categorical values\n",
    "# make them binary dummy variables instead\n",
    "train = pd.get_dummies(train, columns=[\"Pclass\", \"Embarked\", \"Sex\", \"Age_bin\"])\n",
    "test =  pd.get_dummies(test, columns=[\"Pclass\", \"Embarked\", \"Sex\", \"Age_bin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   PassengerId  Survived                                               Name  \\\n",
       "0            1         0                            Braund, Mr. Owen Harris   \n",
       "1            2         1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3         1                             Heikkinen, Miss. Laina   \n",
       "3            4         1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5         0                           Allen, Mr. William Henry   \n",
       "\n",
       "    Age  SibSp  Parch            Ticket     Fare Cabin  Cabin_binary  ...  \\\n",
       "0  22.0      1      0         A/5 21171   7.2500   NaN             0  ...   \n",
       "1  38.0      1      0          PC 17599  71.2833   C85             1  ...   \n",
       "2  26.0      0      0  STON/O2. 3101282   7.9250   NaN             0  ...   \n",
       "3  35.0      1      0            113803  53.1000  C123             1  ...   \n",
       "4  35.0      0      0            373450   8.0500   NaN             0  ...   \n",
       "\n",
       "   Pclass_2  Pclass_3  Embarked_C  Embarked_Q  Embarked_S  Sex_female  \\\n",
       "0         0         1           0           0           1           0   \n",
       "1         0         0           1           0           0           1   \n",
       "2         0         1           0           0           1           1   \n",
       "3         0         0           0           0           1           1   \n",
       "4         0         1           0           0           1           0   \n",
       "\n",
       "   Sex_male  Age_bin_adult  Age_bin_child  Age_bin_old  \n",
       "0         1              1              0            0  \n",
       "1         0              1              0            0  \n",
       "2         0              1              0            0  \n",
       "3         0              1              0            0  \n",
       "4         1              1              0            0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Name</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Cabin_binary</th>\n      <th>...</th>\n      <th>Pclass_2</th>\n      <th>Pclass_3</th>\n      <th>Embarked_C</th>\n      <th>Embarked_Q</th>\n      <th>Embarked_S</th>\n      <th>Sex_female</th>\n      <th>Sex_male</th>\n      <th>Age_bin_adult</th>\n      <th>Age_bin_child</th>\n      <th>Age_bin_old</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 22 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "source": [
    "# Drop uninformative columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PassengerId, Name, and Ticket are practically unique for each individual and thus unusable for predictions\n",
    "# Cabin has a lot of missing values and a lot of unique values. Dropping the columns\n",
    "\n",
    "uninformative_cols = [\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\", \"Parch\", \"SibSp\", \"Embarked_C\", \"Embarked_Q\", \"Embarked_S\", \"Age\", \"Fare\", \"Pclass_2\", \"Age_bin_adult\"] #\n",
    "train = train.drop(columns=uninformative_cols)\n",
    "test = test.drop(columns=uninformative_cols)\n",
    "\n",
    "# Could Cabin be made informative with some feature engineering?"
   ]
  },
  {
   "source": [
    "# Readying the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make subset of training data containing everything except the label\n",
    "X = train.loc[:, train.columns != \"Survived\"]\n",
    "# Make subset containing only the label\n",
    "Y = train[\"Survived\"]\n",
    "X_test = test.loc[:, train.columns != \"Survived\"]\n",
    "Y_test = test[\"Survived\"]"
   ]
  },
  {
   "source": [
    ".. That was not very impressive. Our expectation of performance was horribly miscalibrated, as we fared much worse on the test set than on our training set. Our model also seems to overpredict survival on the test data.\n",
    "\n",
    "Now it's your turn to do better\n",
    "\n",
    "__Exercises__:\n",
    "\n",
    "Discuss:\n",
    "\n",
    "- How can you get a better estimate of the out-of-sample performance?\n",
    "- How can you reduce overfitting to the training data?\n",
    "- Do you need different strategies for model creation for the different sizes of dataset?\n",
    "    - If so, what would you do differently?\n",
    "\n",
    "Code:\n",
    "\n",
    "- For each partition (i.e. each dataset) create at least 3 different models that you expect to generalize well. Evaluate them on the training sample using some form of model selection (cross-validated performance, held-out data, information criteria etc.) and choose one to test on the testing set. Your goal is to create the best performing, most well-calibrated model, ie. training performance should be close to testing performance (and performance should of course be high!). \n",
    "- Test how good performance you can get on the small datasets with clever optimization and regularization.\n",
    "\n",
    "For next time:\n",
    "\n",
    "- In your study groups, prepare a 3-5 min presentation on something interesting about your solution: Did you create some cool functions for preprocessing, test an exciting new type of model, set everything up to be run from the command line, or perhaps you're just really excited about the performance of your model. No need for slideshows, but feel free to show code.\n",
    "\n",
    "---\n",
    "\n",
    "Tips to get started:\n",
    "- Visualization can often be a good way to get started: how is the distribution of the variables? are any of them highly correlated?\n",
    "- Instead of training and testing on the whole training data, implement a form of cross-validation ([sk-learn makes it easy](https://scikit-learn.org/stable/modules/cross_validation.html#computing-cross-validated-metrics))\n",
    "- Remember ridge regularization from last week? [Try it](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html)\n",
    "- Check out a list of models in sk-learn [here](https://scikit-learn.org/stable/supervised_learning.html)\n",
    "- Lost or out of ideas? Take some inspiration from entries in the [original Kaggle challenge](https://www.kaggle.com/c/titanic/code)\n",
    "\n",
    "Things to try:\n",
    "- You might be able to get more information out of the predictors if you do some feature engineering. Perhaps add a column indicating whether the person had a cabin or not, or one calculating the family size?\n",
    "- Calculating information criteriais not entirely straight-forward in sk-learn. [This tutorial](https://machinelearningmastery.com/probabilistic-model-selection-measures/) might help\n",
    "- The outcome (survival) is not completely balanced. Over-/under-sampling might help\n",
    "- Ensemble models often generalize better than single models. Try one of the methods [here](https://scikit-learn.org/stable/modules/ensemble.html)\n",
    "- Don't feel restricted to sk-learn. Feel to make a Bayesian model in [PyMC3](https://github.com/pymc-devs/pymc3) or any other framework you want\n",
    "- High-performance interpretable models are all the rage right now. [Try one of them!](https://github.com/interpretml/interpret) \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Main Function\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mean = 0.8044728291792635, sd = 0.022943960522039293\n",
      "mean = 0.8012275472319912, sd = 0.028849232501459147\n",
      "mean = 0.796989832829095, sd = 0.039685735472306624\n",
      "mean = 0.8078857384222832, sd = 0.025259262024870933\n",
      "mean = 0.8033635625770648, sd = 0.011687311338543074\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'LogisticRegression': {'acc_train': 0.8103254769921436,\n",
       "  'acc_test': 0.9473684210526315,\n",
       "  'mean_cross': 0.8044728291792635,\n",
       "  'std_cross': 0.022943960522039293,\n",
       "  'conf_mat': array([[477,  72],\n",
       "         [ 97, 245]], dtype=int64)},\n",
       " 'RandomForestClassifier': {'acc_train': 0.8439955106621774,\n",
       "  'acc_test': 0.9234449760765551,\n",
       "  'mean_cross': 0.8012275472319912,\n",
       "  'std_cross': 0.028849232501459147,\n",
       "  'conf_mat': array([[502,  47],\n",
       "         [ 92, 250]], dtype=int64)},\n",
       " 'MLPClassifier': {'acc_train': 0.8372615039281706,\n",
       "  'acc_test': 0.9043062200956937,\n",
       "  'mean_cross': 0.796989832829095,\n",
       "  'std_cross': 0.039685735472306624,\n",
       "  'conf_mat': array([[509,  40],\n",
       "         [105, 237]], dtype=int64)},\n",
       " 'RidgeClassifier': {'acc_train': 0.8092031425364759,\n",
       "  'acc_test': 0.9784688995215312,\n",
       "  'mean_cross': 0.8078857384222832,\n",
       "  'std_cross': 0.025259262024870933,\n",
       "  'conf_mat': array([[484,  65],\n",
       "         [105, 237]], dtype=int64)},\n",
       " 'AdaBoostClassifier': {'acc_train': 0.813692480359147,\n",
       "  'acc_test': 0.937799043062201,\n",
       "  'mean_cross': 0.8033635625770648,\n",
       "  'std_cross': 0.011687311338543074,\n",
       "  'conf_mat': array([[464,  85],\n",
       "         [ 81, 261]], dtype=int64)}}"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "import re\n",
    "\n",
    "def get_cross(model_inst, X, Y, cv = 8, scoring = \"f1_weighted\"):\n",
    "    model = model_inst\n",
    "    model.fit(X, Y)\n",
    "    yhat = model.predict(X)\n",
    "    acc_train = accuracy_score(Y, yhat)\n",
    "    yhat_test = model.predict(X_test)\n",
    "    acc_test = accuracy_score(Y_test, yhat_test)\n",
    "    scores = cross_val_score(model_inst, X, Y, cv=8, scoring = \"f1_weighted\")\n",
    "    print(f\"mean = {np.mean(scores)}, sd = {np.std(scores)}\")\n",
    "    return {\"acc_train\": acc_train, \"acc_test\": acc_test, \"mean_cross\": np.mean(scores), \"std_cross\": np.std(scores), \"conf_mat\": confusion_matrix(Y, yhat)}\n",
    "\n",
    "### NESTED DICT APPROACH:\n",
    "\n",
    "list_of_models = [LogisticRegression(), RandomForestClassifier(n_estimators = 60, n_jobs = -1, random_state = 42), MLPClassifier(solver = \"adam\", alpha = 0.001, hidden_layer_sizes=(1000,100)), RidgeClassifier(), AdaBoostClassifier()]\n",
    "\n",
    "model_performance = {re.split(\"\\(\", str(i))[0]: get_cross(i, X, Y) for i in list_of_models}\n",
    "\n",
    "model_performance"
   ]
  },
  {
   "source": [
    "# Indexing the dictionary"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8092031425364759"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "model_performance[\"RidgeClassifier\"][\"acc_train\"]"
   ]
  },
  {
   "source": [
    "## But obviously, you can't interpret these and look under the hood...\n",
    "# OR CAN YOU?!\n",
    "Introducing glassbox modeling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<!-- http://127.0.0.1:7001/2369798754848/ -->\n<iframe src=\"http://127.0.0.1:7001/2369798754848/\" width=100% height=800 frameBorder=\"0\"></iframe>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<!-- http://127.0.0.1:7001/2369798754416/ -->\n<iframe src=\"http://127.0.0.1:7001/2369798754416/\" width=100% height=800 frameBorder=\"0\"></iframe>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "from interpret.glassbox import LogisticRegression, ExplainableBoostingClassifier\n",
    "#from interpret.greybox import DecisionTreeClassifier\n",
    "from interpret import show\n",
    "\n",
    "ebm_log = LogisticRegression()\n",
    "ebm_log.fit(X, Y)\n",
    "\n",
    "emb_exp = ExplainableBoostingClassifier()\n",
    "emb_exp.fit(X,Y)\n",
    "\n",
    "ebm_global = emb_exp.explain_global()\n",
    "show(ebm_global)\n",
    "\n",
    "ebm_global = ebm_log.explain_global()\n",
    "show(ebm_global)\n",
    "\n",
    "# or substitute with LogisticRegression, DecisionTreeClassifier, RuleListClassifier, ...\n",
    "# EBM supports pandas dataframes, numpy arrays, and handles \"string\" data natively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy on test data: 0.930622009569378\n"
     ]
    }
   ],
   "source": [
    "y_hat_test = emb_exp.predict(X_test)\n",
    "print(f\"Accuracy on test data: {accuracy_score(Y_test, y_hat_test)}\")\n",
    "#confusion_matrix(Y_test, y_hat_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[252,  14],\n",
       "       [ 15, 137]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "confusion_matrix(Y_test, y_hat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<!-- http://127.0.0.1:7001/2369890158480/ -->\n<iframe src=\"http://127.0.0.1:7001/2369890158480/\" width=100% height=800 frameBorder=\"0\"></iframe>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy on test data: 0.9808612440191388\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[263,   3],\n",
       "       [  5, 147]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "from interpret.glassbox import ClassificationTree\n",
    "\n",
    "emb_ct = ClassificationTree()\n",
    "emb_ct.fit(X, Y)\n",
    "\n",
    "ebm_global = emb_ct.explain_global()\n",
    "show(ebm_global)\n",
    "\n",
    "y_hat_test = emb_ct.predict(X_test)\n",
    "print(f\"Accuracy on test data: {accuracy_score(Y_test, y_hat_test)}\")\n",
    "confusion_matrix(Y_test, y_hat_test)\n"
   ]
  },
  {
   "source": [
    "# What would Bayes have done?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import arviz as az\n",
    "import pymc3 as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "# Initialize random number generator\n",
    "RANDOM_SEED = 8927\n",
    "np.random.seed(RANDOM_SEED)\n",
    "az.style.use(\"arviz-darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['Survived', 'Cabin_binary', 'Family_size', 'Pclass_1', 'Pclass_3',\n",
       "       'Sex_female', 'Sex_male', 'Age_bin_child', 'Age_bin_old'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "columns = train.columns\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nYou can find the C code in this temporary file: C:\\Users\\Mikkel\\AppData\\Local\\Temp\\theano_compilation_error_r6196852\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "Exception",
     "evalue": "(\"Compilation failed (return status=1): C:\\\\Users\\\\Mikkel\\\\AppData\\\\Local\\\\Temp\\\\ccFDF4ZB.o: In function `run':\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:99: undefined reference to `__imp__Py_NoneStruct'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:124: undefined reference to `__imp_PyExc_ValueError'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:130: undefined reference to `__imp_PyExc_RuntimeError'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:158: undefined reference to `__imp_PyExc_NotImplementedError'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:195: undefined reference to `__imp__Py_NoneStruct'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:210: undefined reference to `__imp_PyExc_ValueError'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:479: undefined reference to `__imp_PyExc_NotImplementedError'\\r. C:\\\\Users\\\\Mikkel\\\\AppData\\\\Local\\\\Temp\\\\ccFDF4ZB.o: In function `_Py_INCREF':\\r. C:/Users/Mikkel/anaconda3/envs/ds/include/object.h:459: undefined reference to `__imp__Py_NoneStruct'\\r. C:\\\\Users\\\\Mikkel\\\\AppData\\\\Local\\\\Temp\\\\ccFDF4ZB.o: In function `run':\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:485: undefined reference to `__imp_PyExc_RuntimeError'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:244: undefined reference to `__imp_PyExc_NotImplementedError'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:265: undefined reference to `__imp_PyExc_RuntimeError'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:173: undefined reference to `__imp_PyExc_TypeError'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:179: undefined reference to `__imp_PyExc_RuntimeError'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:515: undefined reference to `__imp__Py_NoneStruct'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:514: undefined reference to `__imp__Py_NoneStruct'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:516: undefined reference to `__imp__Py_NoneStruct'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:259: undefined reference to `__imp_PyExc_TypeError'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:279: undefined reference to `__imp__Py_NoneStruct'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:294: undefined reference to `__imp_PyExc_ValueError'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:328: undefined reference to `__imp_PyExc_NotImplementedError'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:349: undefined reference to `__imp_PyExc_RuntimeError'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:216: undefined reference to `__imp_PyExc_RuntimeError'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:343: undefined reference to `__imp_PyExc_TypeError'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:300: undefined reference to `__imp_PyExc_RuntimeError'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:397: undefined reference to `__imp_PyExc_RuntimeError'\\r. C:\\\\Users\\\\Mikkel\\\\AppData\\\\Local\\\\Temp\\\\ccFDF4ZB.o: In function `instantiate':\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:550: undefined reference to `__imp_PyExc_TypeError'\\r. C:\\\\Users\\\\Mikkel\\\\AppData\\\\Local\\\\Temp\\\\ccFDF4ZB.o: In function `_import_array':\\r. C:/Users/Mikkel/anaconda3/envs/ds/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1479: undefined reference to `__imp_PyCapsule_Type'\\r. C:/Users/Mikkel/anaconda3/envs/ds/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1480: undefined reference to `__imp_PyExc_RuntimeError'\\r. C:\\\\Users\\\\Mikkel\\\\AppData\\\\Local\\\\Temp\\\\ccFDF4ZB.o: In function `PyInit_m31975b6dadb59d49af3f2b36405378825884299512ee0ed9081be33fa591d30d':\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:583: undefined reference to `__imp_PyExc_ImportError'\\r. C:\\\\Users\\\\Mikkel\\\\AppData\\\\Local\\\\Temp\\\\ccFDF4ZB.o: In function `_import_array':\\r. C:/Users/Mikkel/anaconda3/envs/ds/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1511: undefined reference to `__imp_PyExc_RuntimeError'\\r. C:/Users/Mikkel/anaconda3/envs/ds/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1495: undefined reference to `__imp_PyExc_RuntimeError'\\r. C:/Users/Mikkel/anaconda3/envs/ds/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1501: undefined reference to `__imp_PyExc_RuntimeError'\\r. C:/Users/Mikkel/anaconda3/envs/ds/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1523: undefined reference to `__imp_PyExc_RuntimeError'\\r. C:/Users/Mikkel/anaconda3/envs/ds/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1475: undefined reference to `__imp_PyExc_AttributeError'\\r. C:/Users/Mikkel/anaconda3/envs/ds/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1487: undefined reference to `__imp_PyExc_RuntimeError'\\r. collect2.exe: error: ld returned 1 exit status\\r. \", 'FunctionGraph(Elemwise{true_div,no_inplace}(TensorConstant{1.0}, TensorConstant{1.0}))')",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-e13f7750d349>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# Priors for unknown model parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"alpha\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mbeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# shape = 3 since we have 3 predictors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds\\lib\\site-packages\\pymc3\\distributions\\distribution.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[0mdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[0mdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds\\lib\\site-packages\\pymc3\\distributions\\distribution.py\u001b[0m in \u001b[0;36mdist\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[0mdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m         \u001b[0mdist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds\\lib\\site-packages\\pymc3\\distributions\\continuous.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, mu, sigma, tau, sd, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_tensor_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloatX\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtau\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m         \u001b[0massert_negative_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sigma\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Normal\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds\\lib\\site-packages\\theano\\tensor\\var.py\u001b[0m in \u001b[0;36m__rtruediv__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__rtruediv__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrue_div\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__rfloordiv__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds\\lib\\site-packages\\theano\\graph\\op.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_test_value\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"off\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m             \u001b[0mcompute_test_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_output\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds\\lib\\site-packages\\theano\\graph\\op.py\u001b[0m in \u001b[0;36mcompute_test_value\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[1;31m# Create a thunk that performs the computation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m     \u001b[0mthunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_thunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_map\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_map\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mno_recycling\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m     \u001b[0mthunk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstorage_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[0mthunk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstorage_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds\\lib\\site-packages\\theano\\graph\\op.py\u001b[0m in \u001b[0;36mmake_thunk\u001b[1;34m(self, node, storage_map, compute_map, no_recycling, impl)\u001b[0m\n\u001b[0;32m    632\u001b[0m             )\n\u001b[0;32m    633\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_c_thunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_map\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_map\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mno_recycling\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mNotImplementedError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMethodNotDefined\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m                 \u001b[1;31m# We requested the c code, so don't catch the error.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds\\lib\\site-packages\\theano\\graph\\op.py\u001b[0m in \u001b[0;36mmake_c_thunk\u001b[1;34m(self, node, storage_map, compute_map, no_recycling)\u001b[0m\n\u001b[0;32m    598\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Disabling C code for {self} due to unsupported float16\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"float16\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         outputs = cl.make_thunk(\n\u001b[0m\u001b[0;32m    601\u001b[0m             \u001b[0minput_storage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_storage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds\\lib\\site-packages\\theano\\link\\c\\basic.py\u001b[0m in \u001b[0;36mmake_thunk\u001b[1;34m(self, input_storage, output_storage, storage_map)\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \"\"\"\n\u001b[0;32m   1202\u001b[0m         \u001b[0minit_tasks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_init_tasks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1203\u001b[1;33m         cthunk, module, in_storage, out_storage, error_storage = self.__compile__(\n\u001b[0m\u001b[0;32m   1204\u001b[0m             \u001b[0minput_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_map\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1205\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds\\lib\\site-packages\\theano\\link\\c\\basic.py\u001b[0m in \u001b[0;36m__compile__\u001b[1;34m(self, input_storage, output_storage, storage_map)\u001b[0m\n\u001b[0;32m   1136\u001b[0m         \u001b[0minput_storage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_storage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m         \u001b[0moutput_storage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_storage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1138\u001b[1;33m         thunk, module = self.cthunk_factory(\n\u001b[0m\u001b[0;32m   1139\u001b[0m             \u001b[0merror_storage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1140\u001b[0m             \u001b[0minput_storage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds\\lib\\site-packages\\theano\\link\\c\\basic.py\u001b[0m in \u001b[0;36mcthunk_factory\u001b[1;34m(self, error_storage, in_storage, out_storage, storage_map)\u001b[0m\n\u001b[0;32m   1632\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode_order\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1633\u001b[0m                 \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_map\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1634\u001b[1;33m             \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_module_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule_from_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlnk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1635\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1636\u001b[0m         \u001b[0mvars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morphans\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds\\lib\\site-packages\\theano\\link\\c\\cmodule.py\u001b[0m in \u001b[0;36mmodule_from_key\u001b[1;34m(self, key, lnk)\u001b[0m\n\u001b[0;32m   1189\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m                 \u001b[0mlocation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlimport_workdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m                 \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlnk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile_cmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1192\u001b[0m                 \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds\\lib\\site-packages\\theano\\link\\c\\basic.py\u001b[0m in \u001b[0;36mcompile_cmodule\u001b[1;34m(self, location)\u001b[0m\n\u001b[0;32m   1541\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1542\u001b[0m                 \u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"LOCATION {location}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1543\u001b[1;33m                 module = c_compiler.compile_str(\n\u001b[0m\u001b[0;32m   1544\u001b[0m                     \u001b[0mmodule_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode_hash\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1545\u001b[0m                     \u001b[0msrc_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msrc_code\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ds\\lib\\site-packages\\theano\\link\\c\\cmodule.py\u001b[0m in \u001b[0;36mcompile_str\u001b[1;34m(module_name, src_code, location, include_dirs, lib_dirs, libs, preargs, py_module, hide_symbols)\u001b[0m\n\u001b[0;32m   2544\u001b[0m             \u001b[1;31m# difficult to read.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2545\u001b[0m             \u001b[0mcompile_stderr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompile_stderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\". \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2546\u001b[1;33m             raise Exception(\n\u001b[0m\u001b[0;32m   2547\u001b[0m                 \u001b[1;34mf\"Compilation failed (return status={status}): {compile_stderr}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2548\u001b[0m             )\n",
      "\u001b[1;31mException\u001b[0m: (\"Compilation failed (return status=1): C:\\\\Users\\\\Mikkel\\\\AppData\\\\Local\\\\Temp\\\\ccFDF4ZB.o: In function `run':\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:99: undefined reference to `__imp__Py_NoneStruct'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:124: undefined reference to `__imp_PyExc_ValueError'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:130: undefined reference to `__imp_PyExc_RuntimeError'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:158: undefined reference to `__imp_PyExc_NotImplementedError'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:195: undefined reference to `__imp__Py_NoneStruct'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:210: undefined reference to `__imp_PyExc_ValueError'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:479: undefined reference to `__imp_PyExc_NotImplementedError'\\r. C:\\\\Users\\\\Mikkel\\\\AppData\\\\Local\\\\Temp\\\\ccFDF4ZB.o: In function `_Py_INCREF':\\r. C:/Users/Mikkel/anaconda3/envs/ds/include/object.h:459: undefined reference to `__imp__Py_NoneStruct'\\r. C:\\\\Users\\\\Mikkel\\\\AppData\\\\Local\\\\Temp\\\\ccFDF4ZB.o: In function `run':\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:485: undefined reference to `__imp_PyExc_RuntimeError'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:244: undefined reference to `__imp_PyExc_NotImplementedError'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:265: undefined reference to `__imp_PyExc_RuntimeError'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:173: undefined reference to `__imp_PyExc_TypeError'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:179: undefined reference to `__imp_PyExc_RuntimeError'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:515: undefined reference to `__imp__Py_NoneStruct'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:514: undefined reference to `__imp__Py_NoneStruct'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:516: undefined reference to `__imp__Py_NoneStruct'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:259: undefined reference to `__imp_PyExc_TypeError'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:279: undefined reference to `__imp__Py_NoneStruct'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:294: undefined reference to `__imp_PyExc_ValueError'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:328: undefined reference to `__imp_PyExc_NotImplementedError'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:349: undefined reference to `__imp_PyExc_RuntimeError'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:216: undefined reference to `__imp_PyExc_RuntimeError'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:343: undefined reference to `__imp_PyExc_TypeError'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:300: undefined reference to `__imp_PyExc_RuntimeError'\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:397: undefined reference to `__imp_PyExc_RuntimeError'\\r. C:\\\\Users\\\\Mikkel\\\\AppData\\\\Local\\\\Temp\\\\ccFDF4ZB.o: In function `instantiate':\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:550: undefined reference to `__imp_PyExc_TypeError'\\r. C:\\\\Users\\\\Mikkel\\\\AppData\\\\Local\\\\Temp\\\\ccFDF4ZB.o: In function `_import_array':\\r. C:/Users/Mikkel/anaconda3/envs/ds/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1479: undefined reference to `__imp_PyCapsule_Type'\\r. C:/Users/Mikkel/anaconda3/envs/ds/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1480: undefined reference to `__imp_PyExc_RuntimeError'\\r. C:\\\\Users\\\\Mikkel\\\\AppData\\\\Local\\\\Temp\\\\ccFDF4ZB.o: In function `PyInit_m31975b6dadb59d49af3f2b36405378825884299512ee0ed9081be33fa591d30d':\\r. C:/Users/Mikkel/AppData/Local/Theano/compiledir_Windows-10-10.0.19041-SP0-Intel64_Family_6_Model_142_Stepping_10_GenuineIntel-3.8.5-64/tmptbnaso1c/mod.cpp:583: undefined reference to `__imp_PyExc_ImportError'\\r. C:\\\\Users\\\\Mikkel\\\\AppData\\\\Local\\\\Temp\\\\ccFDF4ZB.o: In function `_import_array':\\r. C:/Users/Mikkel/anaconda3/envs/ds/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1511: undefined reference to `__imp_PyExc_RuntimeError'\\r. C:/Users/Mikkel/anaconda3/envs/ds/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1495: undefined reference to `__imp_PyExc_RuntimeError'\\r. C:/Users/Mikkel/anaconda3/envs/ds/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1501: undefined reference to `__imp_PyExc_RuntimeError'\\r. C:/Users/Mikkel/anaconda3/envs/ds/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1523: undefined reference to `__imp_PyExc_RuntimeError'\\r. C:/Users/Mikkel/anaconda3/envs/ds/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1475: undefined reference to `__imp_PyExc_AttributeError'\\r. C:/Users/Mikkel/anaconda3/envs/ds/lib/site-packages/numpy/core/include/numpy/__multiarray_api.h:1487: undefined reference to `__imp_PyExc_RuntimeError'\\r. collect2.exe: error: ld returned 1 exit status\\r. \", 'FunctionGraph(Elemwise{true_div,no_inplace}(TensorConstant{1.0}, TensorConstant{1.0}))')"
     ]
    }
   ],
   "source": [
    "# theano tensor import. \n",
    "import theano.tensor as T\n",
    "\n",
    "# logistic \n",
    "def logistic(l):\n",
    "    return 1 / (1 + T.exp(-l))\n",
    "\n",
    "# make the model\n",
    "basic_model = pm.Model()\n",
    "\n",
    "with basic_model:\n",
    "    \n",
    "    #data = pm.Data('data', x)\n",
    "    \n",
    "    # Priors for unknown model parameters\n",
    "    alpha = pm.Normal(\"alpha\", mu = 0, sigma = 1)\n",
    "    beta = pm.Normal(\"beta\", mu = 0, sigma = 1, shape = 9) # shape = 3 since we have 3 predictors. \n",
    "    \n",
    "    # Expected value of outcome\n",
    "    mu = alpha + beta[0] * train[columns[1]].values + beta[1] * train[columns[2]].values + beta[2] * train[columns[3]].values + beta[3] * train[columns[4]].values + beta[4] * train[columns[5]].values + beta[5] * train[columns[6]].values + beta[5] * train[columns[6]].values + beta[6] * train[columns[7]].values + beta[7] * train[columns[9]].values + beta[8] * train[columns[10]].values\n",
    "\n",
    "    # Likelihood (sampling distribution) of observations\n",
    "    Y_obs = pm.Bernoulli('Y_obs', p=logistic(mu), observed = train[columns[0]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_estimate = pm.find_MAP(model = basic_model)\n",
    "map_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with basic_model:\n",
    "    # instantiate sampler\n",
    "    step = pm.Slice()\n",
    "\n",
    "    # draw 5000 posterior samples\n",
    "    trace = pm.sample(5000, step=step, return_inferencedata=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with basic_model:\n",
    "    az.plot_trace(trace);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with basic_model:\n",
    "    display(az.summary(trace, round_to=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}